{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000bGenerative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key='YOUR API KEY HERE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n",
    "response = get_completion(\"What is the capital of Germany?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the simulation of human intelligence in machines designed to think and learn, with applications in fields such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memorial University (MUN) has experienced a 4.6% overall decrease in enrolment and a significant 23.5% drop in international enrolment this fall compared to the previous year, leading to a $6 million loss in revenue and potential further budget cuts. Earlier, MUN had already announced 20 layoffs in July. Additionally, international student enrolment in Atlantic Canada has declined by 28% year-over-year.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice.\n",
    "text = \"\"\"\n",
    "Memorial University (MUN) has reported a 4.6% decrease in total enrolment and a 23.5% decrease in international enrolment this fall compared to the 2024 fall semester resulting in $6M in lost revenue that could bring further cuts. MUN previously announced 20 layoffs back in July. Atlantic Canada international student enrolment is down 28% year-over-year.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n",
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 29  \n",
      "Location: San Francisco\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Extract the age and location from the same text.\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the age and location from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Va a llover pronto.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish.\n",
    "text = \"It's going to rain soon.\"\n",
    "\n",
    "prompt = f\"Translate the following text to Spanish:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in the misty mountains of Eldoria, there lived a dragon named Zephyr. Unlike the other dragons who reveled in hoarding gold and terrorizing villages, Zephyr had a curious mind and a heart full of dreams. He often gazed down from his rocky perch, watching the humans below as they built their towns and crafted wondrous inventions. Among them, he was particularly fascinated by the glowing screens and the strange symbols they tapped on.\n",
      "\n",
      "One day, while exploring a forgotten cave, Zephyr stumbled upon an ancient tome. Its pages were filled with strange symbols and diagrams that seemed to dance before his eyes. As he flipped through the book, he realized it was a guide to coding—a language that could bring ideas to life through the magic of technology. Intrigued, Zephyr decided he would learn to code.\n",
      "\n",
      "At first, it was a daunting task. His massive claws were not suited for the delicate tapping of keys, and his fiery breath often melted the parchment he tried to write on. But Zephyr was determined. He fashioned a makeshift keyboard from stones and twigs, and with each clumsy attempt, he grew more adept. He spent countless nights under the stars, practicing the art of coding, his scales shimmering in the moonlight as he typed out lines of code with his claws.\n",
      "\n",
      "As weeks turned into months, Zephyr began to create simple programs. He started with a basic game that allowed him to simulate flying through the skies, dodging clouds and collecting stars. The thrill of seeing his ideas come to life filled him with joy. He shared his creations with the other dragons, who were initially skeptical. But when they saw the game in action, their roars of laughter echoed through the mountains, and they began to see Zephyr in a new light.\n",
      "\n",
      "Encouraged by their enthusiasm, Zephyr decided to take on a bigger challenge. He wanted to create something that would help the humans and dragons coexist peacefully. After much thought, he envisioned a platform where dragons could communicate with humans, sharing their wisdom and stories while learning about the human world in return.\n",
      "\n",
      "With determination, Zephyr coded day and night, pouring his heart into the project. He faced many obstacles—bugs that made his program crash, misunderstandings in the code that led to hilarious mishaps. But with each setback, he learned and grew stronger. Finally, after what felt like an eternity, he completed his masterpiece: a website called \"DragonSpeak.\"\n",
      "\n",
      "The day he launched DragonSpeak, Zephyr invited both dragons and humans to gather at the foot of his mountain. With a flick of his tail, he projected the website into the sky, where it shimmered like a constellation. The humans gasped in awe, and the dragons roared in excitement. They watched as the platform came to life, allowing them to send messages, share stories, and even play games together.\n",
      "\n",
      "As the sun set, casting a golden hue over the valley, dragons and humans began to interact. They shared tales of bravery, exchanged knowledge, and even collaborated on projects. Zephyr watched with pride as friendships blossomed, bridging the gap between their worlds.\n",
      "\n",
      "From that day on, Zephyr was no longer just a dragon; he was a pioneer, a bridge-builder, and a symbol of unity. He continued to code, creating new features for DragonSpeak and inspiring others to learn the art of technology. And as he soared through the skies, he knew that he had found his true treasure—not gold or jewels, but the connections he had forged between dragons and humans, a legacy that would last for generations to come.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal limbs reach out,  \n",
      "Stars whisper secrets of old,  \n",
      "In silence, it roams.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space.\n",
    "prompt = \"Write a haiku about a robot exploring space.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a perfect omelette is a skill that combines technique, timing, and a bit of finesse. Here’s a step-by-step guide to help you achieve that fluffy, delicious result:\n",
      "\n",
      "### Ingredients:\n",
      "- 2-3 large eggs (preferably fresh)\n",
      "- Salt (to taste)\n",
      "- Freshly ground black pepper (to taste)\n",
      "- 1-2 tablespoons of butter (or oil)\n",
      "- Optional fillings: cheese, herbs, vegetables, meats, etc.\n",
      "\n",
      "### Equipment:\n",
      "- Non-stick skillet (8-10 inches)\n",
      "- Whisk or fork\n",
      "- Spatula\n",
      "- Bowl\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Prep Your Ingredients:**\n",
      "   - If you’re using fillings (like cheese, herbs, or vegetables), prepare them in advance. Chop vegetables finely and pre-cook any that require longer cooking times (like mushrooms or bell peppers).\n",
      "\n",
      "2. **Whisk the Eggs:**\n",
      "   - Crack the eggs into a bowl. Add a pinch of salt and pepper. Whisk vigorously until the yolks and whites are fully combined and the mixture is slightly frothy. This incorporates air, which helps create a fluffy texture.\n",
      "\n",
      "3. **Heat the Skillet:**\n",
      "   - Place your non-stick skillet over medium-low heat. Add the butter and let it melt, swirling it around to coat the bottom of the pan evenly. The butter should foam but not brown; if it starts to brown, reduce the heat.\n",
      "\n",
      "4. **Add the Eggs:**\n",
      "   - Once the butter is melted and bubbling, pour the whisked eggs into the skillet. Allow them to sit undisturbed for a few seconds until the edges start to set.\n",
      "\n",
      "5. **Stir Gently:**\n",
      "   - Using a spatula, gently stir the eggs in a circular motion, pulling the cooked edges toward the center while tilting the pan to let the uncooked eggs flow to the edges. This technique helps create a uniform texture.\n",
      "\n",
      "6. **Let It Set:**\n",
      "   - After about 30 seconds of stirring, stop and let the omelette cook undisturbed. You want the bottom to set while the top remains slightly runny. This usually takes about 1-2 minutes, depending on your heat.\n",
      "\n",
      "7. **Add Fillings:**\n",
      "   - When the omelette is mostly set but still slightly runny on top, add your desired fillings to one half of the omelette. Be careful not to overfill, as this can make it difficult to fold.\n",
      "\n",
      "8. **Fold the Omelette:**\n",
      "   - Using your spatula, gently fold the omelette in half over the fillings. Let it cook for another 30 seconds to 1 minute, allowing the cheese to melt and the inside to finish cooking.\n",
      "\n",
      "9. **Plate and Serve:**\n",
      "   - Carefully slide the omelette onto a plate. You can garnish it with fresh herbs or additional seasoning if desired. Serve immediately while it’s warm and fluffy.\n",
      "\n",
      "### Tips for Perfection:\n",
      "- **Egg Quality:** Use the freshest eggs you can find for the best flavor and texture.\n",
      "- **Temperature Control:** Cooking on medium-low heat is key to preventing the eggs from browning too much and ensuring a tender omelette.\n",
      "- **Experiment with Fillings:** Classic combinations include cheese and herbs, but feel free to get creative with your favorite ingredients.\n",
      "- **Practice Makes Perfect:** Don’t be discouraged if your first few attempts aren’t perfect. With practice, you’ll develop a feel for the timing and technique.\n",
      "\n",
      "Enjoy your perfect omelette!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, everyone! Today, we're going to talk about something really cool called \"electron superposition.\" Imagine you have a magic coin. This coin can be both heads and tails at the same time until you look at it. Isn’t that fun?\n",
      "\n",
      "Now, let’s think about electrons, which are tiny particles that are part of everything around us. Just like our magic coin, an electron can be in different places or states at the same time. We call this special ability \"superposition.\"\n",
      "\n",
      "So, if we think of an electron like our magic coin, it can be in two places at once—let's say one place is over here and the other place is over there. But when we try to see where it really is, it has to choose one place, just like when we flip the coin and it lands on either heads or tails.\n",
      "\n",
      "So, superposition is like having a magic coin that can be both heads and tails until we look at it. And that’s how electrons can be in many places or states at the same time until we check on them! Isn’t that amazing?\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher.\n",
    "prompt = \"Explain electron superposition as if you were a kindergarten teacher to their class.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we first need to understand the rate at which the machines produce widgets.\n",
      "\n",
      "From the information given:\n",
      "- 5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "This means that in 5 minutes, each machine produces 1 widget (since 5 machines produce 5 widgets in the same time). Therefore, the rate of production per machine is:\n",
      "\n",
      "\\[\n",
      "\\text{Rate per machine} = \\frac{1 \\text{ widget}}{5 \\text{ minutes}} = 0.2 \\text{ widgets per minute}\n",
      "\\]\n",
      "\n",
      "Now, if we have 100 machines, we can calculate how many widgets they can produce in a minute:\n",
      "\n",
      "\\[\n",
      "\\text{Total production rate of 100 machines} = 100 \\text{ machines} \\times 0.2 \\text{ widgets per minute} = 20 \\text{ widgets per minute}\n",
      "\\]\n",
      "\n",
      "Next, we need to find out how long it will take for these 100 machines to produce 100 widgets. We can use the formula:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{\\text{Total widgets needed}}{\\text{Total production rate}}\n",
      "\\]\n",
      "\n",
      "Substituting the values we have:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{100 \\text{ widgets}}{20 \\text{ widgets per minute}} = 5 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, it would take 100 machines 5 minutes to make 100 widgets.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of flipping a fair coin and getting heads on any single flip is \\( \\frac{1}{2} \\). Each flip of the coin is an independent event, meaning the outcome of one flip does not affect the outcome of another flip.\n",
      "\n",
      "To find the probability of flipping 100 heads in a row, we calculate the probability of getting heads on each of the 100 flips. Since the flips are independent, we multiply the probabilities of each individual flip:\n",
      "\n",
      "\\[\n",
      "P(\\text{100 heads}) = P(\\text{head})^{100} = \\left(\\frac{1}{2}\\right)^{100}\n",
      "\\]\n",
      "\n",
      "Calculating this gives:\n",
      "\n",
      "\\[\n",
      "P(\\text{100 heads}) = \\frac{1}{2^{100}}\n",
      "\\]\n",
      "\n",
      "This is a very small number, approximately \\( 7.888 \\times 10^{-31} \\).\n",
      "\n",
      "It's important to note that the previous flips (the first 100 flips resulting in heads) do not influence the probability of the next 100 flips. The coin is fair, and each flip is independent. Therefore, the probability of flipping another 100 heads remains \\( \\frac{1}{2^{100}} \\).\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution.\n",
    "prompt = \"If you flipped a fair coin 100 times and it landed on heads each time so far, what is the probability of flipping another 100 heads? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial for several reasons:\n",
      "\n",
      "1. **Protection of Personal Information**: It safeguards individuals' personal data from unauthorized access, misuse, or exploitation, ensuring that sensitive information like financial details, health records, and personal identifiers remain confidential.\n",
      "\n",
      "2. **Trust and Reputation**: Organizations that prioritize data privacy build trust with their customers. A strong reputation for protecting data can enhance customer loyalty and attract new clients.\n",
      "\n",
      "3. **Legal Compliance**: Many jurisdictions have laws and regulations (e.g., GDPR, CCPA) that mandate data protection practices. Non-compliance can lead to significant legal penalties and fines.\n",
      "\n",
      "4. **Prevention of Identity Theft**: Effective data privacy measures help prevent identity theft and fraud, protecting individuals from financial loss and emotional distress.\n",
      "\n",
      "5. **Business Continuity**: Data breaches can disrupt business operations. By ensuring data privacy, organizations can mitigate risks and maintain continuity in their operations.\n",
      "\n",
      "6. **Ethical Responsibility**: Organizations have an ethical obligation to respect individuals' privacy rights and handle their data responsibly.\n",
      "\n",
      "7. **Competitive Advantage**: Companies that demonstrate strong data privacy practices can differentiate themselves in the market, appealing to privacy-conscious consumers.\n",
      "\n",
      "In summary, data privacy is essential for protecting individuals, maintaining trust, ensuring compliance, and fostering a secure digital environment.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Data privacy is like the bouncer at the club of your personal information. You want to make sure that only the right people get in, and that the wrong ones are kept out—like that guy who keeps trying to sneak in with a fake ID that says \"I swear I’m not a data broker!\"\n",
      "\n",
      "In today’s world, our data is more valuable than gold. It’s like the new oil, except it doesn’t spill and ruin the environment—unless you count the emotional damage from targeted ads for products you didn’t even know you needed! You know, like that time I got an ad for a “self-help book for people who can’t stop buying self-help books.” \n",
      "\n",
      "Data privacy is important because it protects our personal information from being misused. Imagine if your browsing history was public. Suddenly, your friends would know about that late-night search for “how to make a perfect soufflé” and “why does my cat stare at me like that?” \n",
      "\n",
      "Plus, without data privacy, we’re all just living in a reality show where the producers are corporations trying to sell us stuff we don’t need. “Coming up next: watch as Bob tries to figure out why he’s getting ads for adult diapers after searching for ‘how to fix a leaky faucet!’”\n",
      "\n",
      "So, in short, data privacy is crucial because it keeps our personal lives private, protects us from identity theft, and ensures that we don’t end up as the punchline in someone else’s marketing strategy!\n"
     ]
    }
   ],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change.\n",
    "system_prompt = \"You are a comedian who specializes in satirizing politics.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office as the first president of the United States on April 30, 1789.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication.;\n",
    "def multiply_numbers(a, b):\n",
    "    return a * b\n",
    "\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"multiply_numbers\",\n",
    "                \"description\": \"Multiply two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        elif function_name == \"multiply_numbers\":\n",
    "            result = multiply_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "user_prompt = \"What is 15 times 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
